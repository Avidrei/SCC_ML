{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "868f8649",
   "metadata": {},
   "source": [
    "# Code Description \n",
    "## Exploratory Data Analysis Code \n",
    "- This notebook tackles all code related to loading and training the SCC models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3baeba2",
   "metadata": {},
   "source": [
    "## Part 0 : Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4043afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from thop import profile\n",
    "import torchvision.models as models\n",
    "from transformers import ViTForImageClassification\n",
    "from torchsummary import summary\n",
    "import timm\n",
    "from timm import create_model \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "from ptflops import get_model_complexity_info\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6607bc2",
   "metadata": {},
   "source": [
    "## Dataset Loading Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "618b5834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_paths(data_dir):\n",
    "    image_paths, labels = [], []\n",
    "    class_names = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "    label_map = {name: idx for idx, name in enumerate(class_names)}\n",
    "    valid_exts = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_folder = os.path.join(data_dir, class_name)\n",
    "        for filename in os.listdir(class_folder):\n",
    "            if filename.lower().endswith(valid_exts):\n",
    "                file_path = os.path.join(class_folder, filename)\n",
    "                try:\n",
    "                    Image.open(file_path).verify()\n",
    "                    image_paths.append(file_path)\n",
    "                    labels.append(label_map[class_name])\n",
    "                except Exception:\n",
    "                    print(f\"‚ö†Ô∏è Skipping corrupted file: {file_path}\")\n",
    "\n",
    "    return np.array(image_paths), np.array(labels, dtype=np.int64), class_names\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, img_size=(224, 224), augment=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        if augment:\n",
    "            self.transform = T.Compose([\n",
    "                T.Resize((256, 256)),\n",
    "                T.RandomCrop(img_size),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.RandomVerticalFlip(),\n",
    "                T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = T.Compose([\n",
    "                T.Resize(img_size),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "            ])\n",
    "\n",
    "    def __len__(self): return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "def get_dataloader(image_paths, labels, batch_size=32, augment=False, img_size=(224, 224), shuffle=True):\n",
    "    ds = CustomImageDataset(image_paths, labels, img_size=img_size, augment=augment)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07226195",
   "metadata": {},
   "source": [
    "## Model Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d41be1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from timm import create_model  \n",
    "\n",
    "def build_model(model_name, num_classes=2, pretrained=False):\n",
    "    model_name = model_name.lower()\n",
    "    \n",
    "    if model_name == \"convnext_tiny\":\n",
    "        model = models.convnext_tiny(pretrained=pretrained)\n",
    "        in_features = model.classifier[2].in_features\n",
    "        model.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    elif model_name == \"vit_base_patch16_224\":\n",
    "        model = models.vit_b_16(pretrained=pretrained)\n",
    "        in_features = model.heads.head.in_features\n",
    "        model.heads.head = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    elif model_name.startswith(\"coatnet\"):\n",
    "        model = create_model(model_name, pretrained=pretrained, num_classes=num_classes)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d80eb3",
   "metadata": {},
   "source": [
    "## Model Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3094480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_complexity(model, device, input_size=(3, 224, 224), print_layers=True):\n",
    "    model = model.to(device)\n",
    "    x = torch.randn(1, *input_size).to(device)\n",
    "    flops, params = profile(model, inputs=(x,), verbose=False)\n",
    "    print(f\"üß† Parameters: {params/1e6:.2f} M\")\n",
    "    print(f\"üöÄ FLOPs (1x{input_size[-1]}x{input_size[-1]}): {flops/1e9:.2f} GFLOPs\")\n",
    "    if print_layers:\n",
    "        try:\n",
    "            summary(model, input_size=input_size, device=str(device))\n",
    "        except Exception as e:\n",
    "            print(f\"(summary skipped: {e})\")\n",
    "\n",
    "\n",
    "def measure_latency_throughput(model, device, batch_size=32, input_size=(3,224,224), repeats=50):\n",
    "    model.eval()\n",
    "    dummy = torch.randn(batch_size, *input_size, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(5): _ = model(dummy)\n",
    "    if device.type == \"cuda\": torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(repeats): _ = model(dummy)\n",
    "    if device.type == \"cuda\": torch.cuda.synchronize()\n",
    "    total = time.time() - start\n",
    "    avg_latency_ms = (total / repeats) * 1000.0\n",
    "    throughput = (batch_size * repeats) / total\n",
    "    print(f\"‚ö° Avg Latency: {avg_latency_ms:.2f} ms | üìà Throughput: {throughput:.2f} img/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195577b8",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d6bcdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        preds = outputs.argmax(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, total = 0.0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        preds = outputs.argmax(1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss = running_loss / total\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    rec = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    return val_loss, acc, prec, rec, f1\n",
    "\n",
    "\n",
    "def plot_history(history, title, out_png):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.suptitle(title)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history['train_acc'], label='Train Acc')\n",
    "    plt.plot(history['val_acc'], label='Val Acc')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.grid(True); plt.title('Accuracy')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.grid(True); plt.title('Loss')\n",
    "\n",
    "    plt.tight_layout(rect=[0,0,1,0.95])\n",
    "    plt.savefig(out_png, dpi=140)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fab710e",
   "metadata": {},
   "source": [
    "## Training Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "742225d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_phase(model, phase_name, train_loader, val_loader, device, epochs=10, lr=1e-4, weight_decay=1e-4, out_dir=\"models\", use_amp=True):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scaler = GradScaler() if use_amp else None\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    best_acc, best_state_path, best_full_path = 0.0, os.path.join(out_dir, f\"{phase_name}_best.pth\"), os.path.join(out_dir, f\"{phase_name}_best_full.pth\")\n",
    "\n",
    "    print(f\"\\n‚ñ∂Ô∏è Phase: {phase_name} | epochs={epochs} | lr={lr} | weight_decay={weight_decay}\")\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(f\"\\n--- Epoch {epoch}/{epochs} ---\")\n",
    "        model.train()\n",
    "        running_loss, running_correct, total = 0.0, 0, 0\n",
    "\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            try:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, targets)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                preds = outputs.argmax(1)\n",
    "                running_correct += (preds == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "\n",
    "                if i % 5 == 0:\n",
    "                    print(f\"Batch {i}/{len(train_loader)} | Loss: {running_loss/total:.4f} | Acc: {running_correct/total:.4f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Skipping batch {i} due to error: {e}\")\n",
    "\n",
    "        tr_loss = running_loss / max(total, 1)\n",
    "        tr_acc = running_correct / max(total, 1)\n",
    "\n",
    "        # Validation\n",
    "        va_loss, va_acc, va_prec, va_rec, va_f1 = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        history['train_loss'].append(tr_loss)\n",
    "        history['train_acc'].append(tr_acc)\n",
    "        history['val_loss'].append(va_loss)\n",
    "        history['val_acc'].append(va_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d} | Train Loss: {tr_loss:.4f}, Acc: {tr_acc:.4f} | \"\n",
    "              f\"Val Loss: {va_loss:.4f}, Acc: {va_acc:.4f}, P: {va_prec:.4f}, R: {va_rec:.4f}, F1: {va_f1:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if va_acc > best_acc:\n",
    "            best_acc = va_acc\n",
    "            # Save state dict\n",
    "            torch.save(model.state_dict(), best_state_path)\n",
    "            # Save full model\n",
    "            torch.save(model, best_full_path)\n",
    "\n",
    "    return history, best_acc, best_state_path, best_full_path\n",
    "\n",
    "\n",
    "def run_kfold_training(\n",
    "    model_name: str,\n",
    "    dataset_path: str,\n",
    "    k: int = 5,\n",
    "    epochs_frozen: int = 10,\n",
    "    epochs_ft: int = 20,\n",
    "    batch_size: int = 32,\n",
    "    img_size=(224,224),\n",
    "    base_lr: float = 1e-3,\n",
    "    ft_lr: float = 1e-4,\n",
    "    weight_decay: float = 1e-4,\n",
    "    pretrained=True\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    image_paths, labels, class_names = load_image_paths(dataset_path)\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    model_dir = os.path.join(\"models\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    all_results = []\n",
    "    fold_idx = 0\n",
    "\n",
    "    for train_idx, val_idx in skf.split(image_paths, labels):\n",
    "        fold_idx += 1\n",
    "        print(f\"\\n==================== Fold {fold_idx}/{k} ‚Äî {model_name} ====================\")\n",
    "\n",
    "        fold_dir = os.path.join(model_dir, f\"fold{fold_idx}\")\n",
    "        os.makedirs(fold_dir, exist_ok=True)\n",
    "\n",
    "        train_loader = get_dataloader(image_paths[train_idx], labels[train_idx],\n",
    "                                      batch_size=batch_size, augment=True, img_size=img_size, shuffle=True)\n",
    "        val_loader = get_dataloader(image_paths[val_idx], labels[val_idx],\n",
    "                                    batch_size=batch_size, augment=False, img_size=img_size, shuffle=False)\n",
    "\n",
    "        model = build_model(model_name, num_classes=num_classes, pretrained=pretrained).to(device)\n",
    "\n",
    "        # Freeze backbone\n",
    "        for name, param in model.named_parameters():\n",
    "            param.requires_grad = False\n",
    "        for name, param in model.named_parameters():\n",
    "            if any(key in name for key in ['head', 'classifier', 'fc', 'bn', 'norm']):\n",
    "                param.requires_grad = True\n",
    "\n",
    "        # Phase 1: Frozen backbone\n",
    "        hist_frozen, best_acc_frozen, best_state_frozen, best_full_frozen = run_phase(\n",
    "            model, phase_name=f\"fold{fold_idx}_frozen\",\n",
    "            train_loader=train_loader, val_loader=val_loader,\n",
    "            device=device, epochs=epochs_frozen, lr=base_lr,\n",
    "            weight_decay=weight_decay, out_dir=fold_dir\n",
    "        )\n",
    "\n",
    "        model.load_state_dict(torch.load(best_state_frozen, map_location=device))\n",
    "\n",
    "        # Phase 2: Fine-tune all layers\n",
    "        for p in model.parameters(): p.requires_grad = True\n",
    "        hist_ft, best_acc_ft, best_state_ft, best_full_ft = run_phase(\n",
    "            model, phase_name=f\"fold{fold_idx}_finetune\",\n",
    "            train_loader=train_loader, val_loader=val_loader,\n",
    "            device=device, epochs=epochs_ft, lr=ft_lr,\n",
    "            weight_decay=weight_decay, out_dir=fold_dir\n",
    "        )\n",
    "\n",
    "        model.load_state_dict(torch.load(best_state_ft, map_location=device))\n",
    "        val_loss, val_acc, val_prec, val_rec, val_f1 = evaluate(model, val_loader, nn.CrossEntropyLoss(), device)\n",
    "\n",
    "        all_results.append({\n",
    "            \"fold\": fold_idx,\n",
    "            \"best_acc_frozen\": best_acc_frozen,\n",
    "            \"best_acc_finetune\": best_acc_ft,\n",
    "            \"final_val_acc\": val_acc,\n",
    "            \"final_val_precision\": val_prec,\n",
    "            \"final_val_recall\": val_rec,\n",
    "            \"final_val_f1\": val_f1,\n",
    "            \"best_ckpt_frozen_state\": best_state_frozen,\n",
    "            \"best_ckpt_frozen_full\": best_full_frozen,\n",
    "            \"best_ckpt_finetune_state\": best_state_ft,\n",
    "            \"best_ckpt_finetune_full\": best_full_ft\n",
    "        })\n",
    "\n",
    "        # Cleanup\n",
    "        del model, train_loader, val_loader\n",
    "        if device.type == \"cuda\": torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    # Save results\n",
    "    df = pd.DataFrame(all_results)\n",
    "    csv_name = os.path.join(model_dir, f\"{model_name}_kfold_results.csv\")\n",
    "    df.to_csv(csv_name, index=False)\n",
    "    print(f\"\\nüìÑ Saved results: {csv_name}\")\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(df[\"fold\"], df[\"final_val_acc\"], marker='o')\n",
    "    plt.xlabel(\"Fold\"); plt.ylabel(\"Final Val Accuracy\")\n",
    "    plt.title(f\"{model_name} ‚Äî Accuracy Across Folds (Fine-tuned best)\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(model_dir, f\"{model_name}_kfold_final_acc.png\"), dpi=140)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746aedca",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4ed6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"Dataset\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb2856",
   "metadata": {},
   "source": [
    "- ConVNexT Tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70a36eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Fold 1/5 ‚Äî convnext_tiny ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cauba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cauba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if use_amp else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñ∂Ô∏è Phase: fold1_frozen | epochs=10 | lr=0.001 | weight_decay=0.0001\n",
      "\n",
      "--- Epoch 1/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.6867 | Acc: 0.5625\n",
      "Batch 5/21 | Loss: 0.6102 | Acc: 0.6875\n",
      "Batch 10/21 | Loss: 0.5730 | Acc: 0.6903\n",
      "Batch 15/21 | Loss: 0.5559 | Acc: 0.7031\n",
      "Batch 20/21 | Loss: 0.5473 | Acc: 0.7039\n",
      "Epoch 01 | Train Loss: 0.5473, Acc: 0.7039 | Val Loss: 0.4043, Acc: 0.8133, P: 0.8093, R: 0.8172, F1: 0.8108\n",
      "\n",
      "--- Epoch 2/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3567 | Acc: 0.8438\n",
      "Batch 5/21 | Loss: 0.4255 | Acc: 0.8333\n",
      "Batch 10/21 | Loss: 0.4101 | Acc: 0.8324\n",
      "Batch 15/21 | Loss: 0.4005 | Acc: 0.8340\n",
      "Batch 20/21 | Loss: 0.3857 | Acc: 0.8459\n",
      "Epoch 02 | Train Loss: 0.3857, Acc: 0.8459 | Val Loss: 0.2971, Acc: 0.8916, P: 0.8971, R: 0.8800, F1: 0.8862\n",
      "\n",
      "--- Epoch 3/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3927 | Acc: 0.8438\n",
      "Batch 5/21 | Loss: 0.3690 | Acc: 0.8385\n",
      "Batch 10/21 | Loss: 0.3610 | Acc: 0.8551\n",
      "Batch 15/21 | Loss: 0.3531 | Acc: 0.8633\n",
      "Batch 20/21 | Loss: 0.3471 | Acc: 0.8640\n",
      "Epoch 03 | Train Loss: 0.3471, Acc: 0.8640 | Val Loss: 0.2724, Acc: 0.9096, P: 0.9184, R: 0.8976, F1: 0.9049\n",
      "\n",
      "--- Epoch 4/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3437 | Acc: 0.8438\n",
      "Batch 5/21 | Loss: 0.3642 | Acc: 0.8281\n",
      "Batch 10/21 | Loss: 0.3314 | Acc: 0.8551\n",
      "Batch 15/21 | Loss: 0.3224 | Acc: 0.8613\n",
      "Batch 20/21 | Loss: 0.3171 | Acc: 0.8701\n",
      "Epoch 04 | Train Loss: 0.3171, Acc: 0.8701 | Val Loss: 0.2445, Acc: 0.9157, P: 0.9121, R: 0.9153, F1: 0.9135\n",
      "\n",
      "--- Epoch 5/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2672 | Acc: 0.8750\n",
      "Batch 5/21 | Loss: 0.2922 | Acc: 0.8646\n",
      "Batch 10/21 | Loss: 0.2936 | Acc: 0.8693\n",
      "Batch 15/21 | Loss: 0.2909 | Acc: 0.8711\n",
      "Batch 20/21 | Loss: 0.2890 | Acc: 0.8716\n",
      "Epoch 05 | Train Loss: 0.2890, Acc: 0.8716 | Val Loss: 0.2333, Acc: 0.9096, P: 0.9077, R: 0.9059, F1: 0.9068\n",
      "\n",
      "--- Epoch 6/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2427 | Acc: 0.9062\n",
      "Batch 5/21 | Loss: 0.2563 | Acc: 0.8906\n",
      "Batch 10/21 | Loss: 0.2719 | Acc: 0.8835\n",
      "Batch 15/21 | Loss: 0.2628 | Acc: 0.8926\n",
      "Batch 20/21 | Loss: 0.2709 | Acc: 0.8912\n",
      "Epoch 06 | Train Loss: 0.2709, Acc: 0.8912 | Val Loss: 0.2329, Acc: 0.8916, P: 0.8870, R: 0.8947, F1: 0.8896\n",
      "\n",
      "--- Epoch 7/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2793 | Acc: 0.8750\n",
      "Batch 5/21 | Loss: 0.2562 | Acc: 0.8958\n",
      "Batch 10/21 | Loss: 0.2380 | Acc: 0.9062\n",
      "Batch 15/21 | Loss: 0.2433 | Acc: 0.9043\n",
      "Batch 20/21 | Loss: 0.2564 | Acc: 0.8927\n",
      "Epoch 07 | Train Loss: 0.2564, Acc: 0.8927 | Val Loss: 0.2086, Acc: 0.9277, P: 0.9273, R: 0.9235, F1: 0.9253\n",
      "\n",
      "--- Epoch 8/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1545 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.2058 | Acc: 0.9375\n",
      "Batch 10/21 | Loss: 0.2131 | Acc: 0.9375\n",
      "Batch 15/21 | Loss: 0.2195 | Acc: 0.9219\n",
      "Batch 20/21 | Loss: 0.2510 | Acc: 0.8988\n",
      "Epoch 08 | Train Loss: 0.2510, Acc: 0.8988 | Val Loss: 0.2051, Acc: 0.9096, P: 0.9053, R: 0.9122, F1: 0.9079\n",
      "\n",
      "--- Epoch 9/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2982 | Acc: 0.8750\n",
      "Batch 5/21 | Loss: 0.2421 | Acc: 0.9115\n",
      "Batch 10/21 | Loss: 0.2377 | Acc: 0.9091\n",
      "Batch 15/21 | Loss: 0.2213 | Acc: 0.9199\n",
      "Batch 20/21 | Loss: 0.2404 | Acc: 0.9048\n",
      "Epoch 09 | Train Loss: 0.2404, Acc: 0.9048 | Val Loss: 0.1931, Acc: 0.9217, P: 0.9221, R: 0.9163, F1: 0.9189\n",
      "\n",
      "--- Epoch 10/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1576 | Acc: 0.9375\n",
      "Batch 5/21 | Loss: 0.2587 | Acc: 0.9010\n",
      "Batch 10/21 | Loss: 0.2444 | Acc: 0.9006\n",
      "Batch 15/21 | Loss: 0.2421 | Acc: 0.9062\n",
      "Batch 20/21 | Loss: 0.2452 | Acc: 0.9018\n",
      "Epoch 10 | Train Loss: 0.2452, Acc: 0.9018 | Val Loss: 0.1960, Acc: 0.9277, P: 0.9256, R: 0.9256, F1: 0.9256\n",
      "\n",
      "‚ñ∂Ô∏è Phase: fold1_finetune | epochs=20 | lr=0.0001 | weight_decay=0.0001\n",
      "\n",
      "--- Epoch 1/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_state_frozen, map_location=device))\n",
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if use_amp else None\n",
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3407 | Acc: 0.8125\n",
      "Batch 5/21 | Loss: 0.3029 | Acc: 0.8490\n",
      "Batch 10/21 | Loss: 0.2660 | Acc: 0.8864\n",
      "Batch 15/21 | Loss: 0.3002 | Acc: 0.8750\n",
      "Batch 20/21 | Loss: 0.3050 | Acc: 0.8686\n",
      "Epoch 01 | Train Loss: 0.3050, Acc: 0.8686 | Val Loss: 0.2418, Acc: 0.8855, P: 0.8830, R: 0.8937, F1: 0.8843\n",
      "\n",
      "--- Epoch 2/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2636 | Acc: 0.9062\n",
      "Batch 5/21 | Loss: 0.2482 | Acc: 0.9062\n",
      "Batch 10/21 | Loss: 0.2421 | Acc: 0.9062\n",
      "Batch 15/21 | Loss: 0.2494 | Acc: 0.9004\n",
      "Batch 20/21 | Loss: 0.2477 | Acc: 0.8988\n",
      "Epoch 02 | Train Loss: 0.2477, Acc: 0.8988 | Val Loss: 0.1897, Acc: 0.9398, P: 0.9533, R: 0.9275, F1: 0.9364\n",
      "\n",
      "--- Epoch 3/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1426 | Acc: 0.8750\n",
      "Batch 5/21 | Loss: 0.1498 | Acc: 0.9271\n",
      "Batch 10/21 | Loss: 0.1726 | Acc: 0.9261\n",
      "Batch 15/21 | Loss: 0.1481 | Acc: 0.9395\n",
      "Batch 20/21 | Loss: 0.1456 | Acc: 0.9441\n",
      "Epoch 03 | Train Loss: 0.1456, Acc: 0.9441 | Val Loss: 0.1529, Acc: 0.9337, P: 0.9311, R: 0.9328, F1: 0.9319\n",
      "\n",
      "--- Epoch 4/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0721 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0812 | Acc: 0.9531\n",
      "Batch 10/21 | Loss: 0.0795 | Acc: 0.9631\n",
      "Batch 15/21 | Loss: 0.0970 | Acc: 0.9629\n",
      "Batch 20/21 | Loss: 0.0995 | Acc: 0.9622\n",
      "Epoch 04 | Train Loss: 0.0995, Acc: 0.9622 | Val Loss: 0.1876, Acc: 0.9096, P: 0.9054, R: 0.9143, F1: 0.9082\n",
      "\n",
      "--- Epoch 5/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1128 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.1106 | Acc: 0.9583\n",
      "Batch 10/21 | Loss: 0.0999 | Acc: 0.9602\n",
      "Batch 15/21 | Loss: 0.0865 | Acc: 0.9648\n",
      "Batch 20/21 | Loss: 0.0819 | Acc: 0.9668\n",
      "Epoch 05 | Train Loss: 0.0819, Acc: 0.9668 | Val Loss: 0.1801, Acc: 0.9217, P: 0.9187, R: 0.9204, F1: 0.9196\n",
      "\n",
      "--- Epoch 6/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0490 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0634 | Acc: 0.9688\n",
      "Batch 10/21 | Loss: 0.0567 | Acc: 0.9801\n",
      "Batch 15/21 | Loss: 0.0570 | Acc: 0.9785\n",
      "Batch 20/21 | Loss: 0.0546 | Acc: 0.9819\n",
      "Epoch 06 | Train Loss: 0.0546, Acc: 0.9819 | Val Loss: 0.1657, Acc: 0.9398, P: 0.9357, R: 0.9443, F1: 0.9387\n",
      "\n",
      "--- Epoch 7/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0328 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0503 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0571 | Acc: 0.9801\n",
      "Batch 15/21 | Loss: 0.0500 | Acc: 0.9824\n",
      "Batch 20/21 | Loss: 0.0531 | Acc: 0.9804\n",
      "Epoch 07 | Train Loss: 0.0531, Acc: 0.9804 | Val Loss: 0.2563, Acc: 0.9157, P: 0.9126, R: 0.9237, F1: 0.9147\n",
      "\n",
      "--- Epoch 8/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0791 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0378 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0409 | Acc: 0.9886\n",
      "Batch 15/21 | Loss: 0.0404 | Acc: 0.9902\n",
      "Batch 20/21 | Loss: 0.0376 | Acc: 0.9879\n",
      "Epoch 08 | Train Loss: 0.0376, Acc: 0.9879 | Val Loss: 0.1845, Acc: 0.9337, P: 0.9311, R: 0.9328, F1: 0.9319\n",
      "\n",
      "--- Epoch 9/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0143 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0495 | Acc: 0.9792\n",
      "Batch 10/21 | Loss: 0.0372 | Acc: 0.9858\n",
      "Batch 15/21 | Loss: 0.0465 | Acc: 0.9805\n",
      "Batch 20/21 | Loss: 0.0496 | Acc: 0.9789\n",
      "Epoch 09 | Train Loss: 0.0496, Acc: 0.9789 | Val Loss: 0.1867, Acc: 0.9398, P: 0.9398, R: 0.9359, F1: 0.9377\n",
      "\n",
      "--- Epoch 10/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0135 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0819 | Acc: 0.9740\n",
      "Batch 10/21 | Loss: 0.0574 | Acc: 0.9830\n",
      "Batch 15/21 | Loss: 0.0557 | Acc: 0.9844\n",
      "Batch 20/21 | Loss: 0.0488 | Acc: 0.9879\n",
      "Epoch 10 | Train Loss: 0.0488, Acc: 0.9879 | Val Loss: 0.1807, Acc: 0.9398, P: 0.9398, R: 0.9359, F1: 0.9377\n",
      "\n",
      "--- Epoch 11/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0056 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0202 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0159 | Acc: 0.9972\n",
      "Batch 15/21 | Loss: 0.0256 | Acc: 0.9961\n",
      "Batch 20/21 | Loss: 0.0220 | Acc: 0.9955\n",
      "Epoch 11 | Train Loss: 0.0220, Acc: 0.9955 | Val Loss: 0.2239, Acc: 0.9157, P: 0.9132, R: 0.9132, F1: 0.9132\n",
      "\n",
      "--- Epoch 12/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0028 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0212 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0209 | Acc: 0.9943\n",
      "Batch 15/21 | Loss: 0.0198 | Acc: 0.9941\n",
      "Batch 20/21 | Loss: 0.0213 | Acc: 0.9940\n",
      "Epoch 12 | Train Loss: 0.0213, Acc: 0.9940 | Val Loss: 0.1668, Acc: 0.9639, P: 0.9649, R: 0.9607, F1: 0.9626\n",
      "\n",
      "--- Epoch 13/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0020 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0124 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0161 | Acc: 0.9943\n",
      "Batch 15/21 | Loss: 0.0129 | Acc: 0.9961\n",
      "Batch 20/21 | Loss: 0.0188 | Acc: 0.9940\n",
      "Epoch 13 | Train Loss: 0.0188, Acc: 0.9940 | Val Loss: 0.2586, Acc: 0.9337, P: 0.9296, R: 0.9370, F1: 0.9324\n",
      "\n",
      "--- Epoch 14/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0154 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0129 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0189 | Acc: 0.9943\n",
      "Batch 15/21 | Loss: 0.0180 | Acc: 0.9922\n",
      "Batch 20/21 | Loss: 0.0161 | Acc: 0.9924\n",
      "Epoch 14 | Train Loss: 0.0161, Acc: 0.9924 | Val Loss: 0.2271, Acc: 0.9458, P: 0.9473, R: 0.9411, F1: 0.9438\n",
      "\n",
      "--- Epoch 15/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0030 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0264 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0221 | Acc: 0.9943\n",
      "Batch 15/21 | Loss: 0.0323 | Acc: 0.9902\n",
      "Batch 20/21 | Loss: 0.0383 | Acc: 0.9879\n",
      "Epoch 15 | Train Loss: 0.0383, Acc: 0.9879 | Val Loss: 0.3726, Acc: 0.8855, P: 0.8866, R: 0.8979, F1: 0.8848\n",
      "\n",
      "--- Epoch 16/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0581 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0344 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0284 | Acc: 0.9915\n",
      "Batch 15/21 | Loss: 0.0262 | Acc: 0.9922\n",
      "Batch 20/21 | Loss: 0.0396 | Acc: 0.9894\n",
      "Epoch 16 | Train Loss: 0.0396, Acc: 0.9894 | Val Loss: 0.2358, Acc: 0.9217, P: 0.9221, R: 0.9163, F1: 0.9189\n",
      "\n",
      "--- Epoch 17/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0609 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0400 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0315 | Acc: 0.9886\n",
      "Batch 15/21 | Loss: 0.0292 | Acc: 0.9883\n",
      "Batch 20/21 | Loss: 0.0249 | Acc: 0.9909\n",
      "Epoch 17 | Train Loss: 0.0249, Acc: 0.9909 | Val Loss: 0.2373, Acc: 0.9157, P: 0.9117, R: 0.9216, F1: 0.9144\n",
      "\n",
      "--- Epoch 18/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0217 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0453 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0377 | Acc: 0.9858\n",
      "Batch 15/21 | Loss: 0.0334 | Acc: 0.9863\n",
      "Batch 20/21 | Loss: 0.0319 | Acc: 0.9879\n",
      "Epoch 18 | Train Loss: 0.0319, Acc: 0.9879 | Val Loss: 0.5108, Acc: 0.8976, P: 0.9193, R: 0.8789, F1: 0.8902\n",
      "\n",
      "--- Epoch 19/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0054 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0356 | Acc: 0.9792\n",
      "Batch 10/21 | Loss: 0.0452 | Acc: 0.9830\n",
      "Batch 15/21 | Loss: 0.0341 | Acc: 0.9883\n",
      "Batch 20/21 | Loss: 0.0332 | Acc: 0.9864\n",
      "Epoch 19 | Train Loss: 0.0332, Acc: 0.9864 | Val Loss: 0.2162, Acc: 0.9458, P: 0.9418, R: 0.9494, F1: 0.9447\n",
      "\n",
      "--- Epoch 20/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0080 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0097 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0128 | Acc: 0.9943\n",
      "Batch 15/21 | Loss: 0.0135 | Acc: 0.9941\n",
      "Batch 20/21 | Loss: 0.0177 | Acc: 0.9940\n",
      "Epoch 20 | Train Loss: 0.0177, Acc: 0.9940 | Val Loss: 0.2139, Acc: 0.9337, P: 0.9301, R: 0.9349, F1: 0.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_state_ft, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Fold 2/5 ‚Äî convnext_tiny ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cauba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cauba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if use_amp else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñ∂Ô∏è Phase: fold2_frozen | epochs=10 | lr=0.001 | weight_decay=0.0001\n",
      "\n",
      "--- Epoch 1/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.7048 | Acc: 0.5938\n",
      "Batch 5/21 | Loss: 0.6057 | Acc: 0.6562\n",
      "Batch 10/21 | Loss: 0.5648 | Acc: 0.7074\n",
      "Batch 15/21 | Loss: 0.5319 | Acc: 0.7363\n",
      "Batch 20/21 | Loss: 0.5070 | Acc: 0.7508\n",
      "Epoch 01 | Train Loss: 0.5070, Acc: 0.7508 | Val Loss: 0.3872, Acc: 0.7952, P: 0.8010, R: 0.7745, F1: 0.7812\n",
      "\n",
      "--- Epoch 2/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.4793 | Acc: 0.7500\n",
      "Batch 5/21 | Loss: 0.4120 | Acc: 0.8281\n",
      "Batch 10/21 | Loss: 0.4019 | Acc: 0.8438\n",
      "Batch 15/21 | Loss: 0.3854 | Acc: 0.8457\n",
      "Batch 20/21 | Loss: 0.3759 | Acc: 0.8505\n",
      "Epoch 02 | Train Loss: 0.3759, Acc: 0.8505 | Val Loss: 0.3188, Acc: 0.8614, P: 0.8592, R: 0.8543, F1: 0.8564\n",
      "\n",
      "--- Epoch 3/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3522 | Acc: 0.8438\n",
      "Batch 5/21 | Loss: 0.3138 | Acc: 0.8750\n",
      "Batch 10/21 | Loss: 0.3049 | Acc: 0.8835\n",
      "Batch 15/21 | Loss: 0.3076 | Acc: 0.8809\n",
      "Batch 20/21 | Loss: 0.3110 | Acc: 0.8807\n",
      "Epoch 03 | Train Loss: 0.3110, Acc: 0.8807 | Val Loss: 0.2917, Acc: 0.8916, P: 0.8875, R: 0.8905, F1: 0.8888\n",
      "\n",
      "--- Epoch 4/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2557 | Acc: 0.9062\n",
      "Batch 5/21 | Loss: 0.3175 | Acc: 0.8698\n",
      "Batch 10/21 | Loss: 0.2839 | Acc: 0.8920\n",
      "Batch 15/21 | Loss: 0.3113 | Acc: 0.8711\n",
      "Batch 20/21 | Loss: 0.3082 | Acc: 0.8761\n",
      "Epoch 04 | Train Loss: 0.3082, Acc: 0.8761 | Val Loss: 0.2966, Acc: 0.8735, P: 0.8698, R: 0.8792, F1: 0.8718\n",
      "\n",
      "--- Epoch 5/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2563 | Acc: 0.8750\n",
      "Batch 5/21 | Loss: 0.2711 | Acc: 0.8854\n",
      "Batch 10/21 | Loss: 0.2538 | Acc: 0.8949\n",
      "Batch 15/21 | Loss: 0.2584 | Acc: 0.8945\n",
      "Batch 20/21 | Loss: 0.2777 | Acc: 0.8882\n",
      "Epoch 05 | Train Loss: 0.2777, Acc: 0.8882 | Val Loss: 0.2557, Acc: 0.8916, P: 0.8898, R: 0.8863, F1: 0.8879\n",
      "\n",
      "--- Epoch 6/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3303 | Acc: 0.8750\n",
      "Batch 5/21 | Loss: 0.2762 | Acc: 0.8698\n",
      "Batch 10/21 | Loss: 0.2727 | Acc: 0.8920\n",
      "Batch 15/21 | Loss: 0.2811 | Acc: 0.8789\n",
      "Batch 20/21 | Loss: 0.2655 | Acc: 0.8897\n",
      "Epoch 06 | Train Loss: 0.2655, Acc: 0.8897 | Val Loss: 0.2624, Acc: 0.8976, P: 0.9053, R: 0.8852, F1: 0.8922\n",
      "\n",
      "--- Epoch 7/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2754 | Acc: 0.8750\n",
      "Batch 5/21 | Loss: 0.2477 | Acc: 0.9010\n",
      "Batch 10/21 | Loss: 0.2662 | Acc: 0.8864\n",
      "Batch 15/21 | Loss: 0.2506 | Acc: 0.9023\n",
      "Batch 20/21 | Loss: 0.2490 | Acc: 0.9018\n",
      "Epoch 07 | Train Loss: 0.2490, Acc: 0.9018 | Val Loss: 0.2457, Acc: 0.8916, P: 0.8875, R: 0.8905, F1: 0.8888\n",
      "\n",
      "--- Epoch 8/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1958 | Acc: 0.9375\n",
      "Batch 5/21 | Loss: 0.2549 | Acc: 0.8906\n",
      "Batch 10/21 | Loss: 0.2347 | Acc: 0.9062\n",
      "Batch 15/21 | Loss: 0.2365 | Acc: 0.9062\n",
      "Batch 20/21 | Loss: 0.2497 | Acc: 0.8973\n",
      "Epoch 08 | Train Loss: 0.2497, Acc: 0.8973 | Val Loss: 0.2401, Acc: 0.8976, P: 0.8953, R: 0.8935, F1: 0.8944\n",
      "\n",
      "--- Epoch 9/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2477 | Acc: 0.8438\n",
      "Batch 5/21 | Loss: 0.2171 | Acc: 0.9219\n",
      "Batch 10/21 | Loss: 0.2443 | Acc: 0.9091\n",
      "Batch 15/21 | Loss: 0.2585 | Acc: 0.8965\n",
      "Batch 20/21 | Loss: 0.2502 | Acc: 0.9018\n",
      "Epoch 09 | Train Loss: 0.2502, Acc: 0.9018 | Val Loss: 0.2333, Acc: 0.9036, P: 0.9043, R: 0.8966, F1: 0.8999\n",
      "\n",
      "--- Epoch 10/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3629 | Acc: 0.8438\n",
      "Batch 5/21 | Loss: 0.2400 | Acc: 0.9115\n",
      "Batch 10/21 | Loss: 0.2346 | Acc: 0.9091\n",
      "Batch 15/21 | Loss: 0.2507 | Acc: 0.9023\n",
      "Batch 20/21 | Loss: 0.2430 | Acc: 0.9063\n",
      "Epoch 10 | Train Loss: 0.2430, Acc: 0.9063 | Val Loss: 0.2282, Acc: 0.9036, P: 0.9043, R: 0.8966, F1: 0.8999\n",
      "\n",
      "‚ñ∂Ô∏è Phase: fold2_finetune | epochs=20 | lr=0.0001 | weight_decay=0.0001\n",
      "\n",
      "--- Epoch 1/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_state_frozen, map_location=device))\n",
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if use_amp else None\n",
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2651 | Acc: 0.9375\n",
      "Batch 5/21 | Loss: 0.3483 | Acc: 0.8281\n",
      "Batch 10/21 | Loss: 0.3341 | Acc: 0.8352\n",
      "Batch 15/21 | Loss: 0.2949 | Acc: 0.8594\n",
      "Batch 20/21 | Loss: 0.2834 | Acc: 0.8716\n",
      "Epoch 01 | Train Loss: 0.2834, Acc: 0.8716 | Val Loss: 0.2322, Acc: 0.9217, P: 0.9175, R: 0.9267, F1: 0.9204\n",
      "\n",
      "--- Epoch 2/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1024 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.2114 | Acc: 0.9219\n",
      "Batch 10/21 | Loss: 0.2353 | Acc: 0.9034\n",
      "Batch 15/21 | Loss: 0.2187 | Acc: 0.9102\n",
      "Batch 20/21 | Loss: 0.2020 | Acc: 0.9154\n",
      "Epoch 02 | Train Loss: 0.2020, Acc: 0.9154 | Val Loss: 0.2048, Acc: 0.9096, P: 0.9077, R: 0.9059, F1: 0.9068\n",
      "\n",
      "--- Epoch 3/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1135 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.1323 | Acc: 0.9479\n",
      "Batch 10/21 | Loss: 0.1269 | Acc: 0.9489\n",
      "Batch 15/21 | Loss: 0.1369 | Acc: 0.9473\n",
      "Batch 20/21 | Loss: 0.1405 | Acc: 0.9471\n",
      "Epoch 03 | Train Loss: 0.1405, Acc: 0.9471 | Val Loss: 0.2250, Acc: 0.9096, P: 0.9149, R: 0.8997, F1: 0.9054\n",
      "\n",
      "--- Epoch 4/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0534 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0676 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0856 | Acc: 0.9659\n",
      "Batch 15/21 | Loss: 0.0770 | Acc: 0.9648\n",
      "Batch 20/21 | Loss: 0.0778 | Acc: 0.9683\n",
      "Epoch 04 | Train Loss: 0.0778, Acc: 0.9683 | Val Loss: 0.3333, Acc: 0.9036, P: 0.9182, R: 0.8882, F1: 0.8977\n",
      "\n",
      "--- Epoch 5/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1615 | Acc: 0.9062\n",
      "Batch 5/21 | Loss: 0.1261 | Acc: 0.9531\n",
      "Batch 10/21 | Loss: 0.1107 | Acc: 0.9574\n",
      "Batch 15/21 | Loss: 0.1094 | Acc: 0.9590\n",
      "Batch 20/21 | Loss: 0.0923 | Acc: 0.9668\n",
      "Epoch 05 | Train Loss: 0.0923, Acc: 0.9668 | Val Loss: 0.2347, Acc: 0.9337, P: 0.9347, R: 0.9287, F1: 0.9313\n",
      "\n",
      "--- Epoch 6/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0236 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0638 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0564 | Acc: 0.9858\n",
      "Batch 15/21 | Loss: 0.0475 | Acc: 0.9883\n",
      "Batch 20/21 | Loss: 0.0557 | Acc: 0.9819\n",
      "Epoch 06 | Train Loss: 0.0557, Acc: 0.9819 | Val Loss: 0.3161, Acc: 0.9096, P: 0.9184, R: 0.8976, F1: 0.9049\n",
      "\n",
      "--- Epoch 7/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0731 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0543 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0472 | Acc: 0.9915\n",
      "Batch 15/21 | Loss: 0.0430 | Acc: 0.9902\n",
      "Batch 20/21 | Loss: 0.0409 | Acc: 0.9909\n",
      "Epoch 07 | Train Loss: 0.0409, Acc: 0.9909 | Val Loss: 0.2496, Acc: 0.8976, P: 0.8939, R: 0.9040, F1: 0.8962\n",
      "\n",
      "--- Epoch 8/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0297 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0441 | Acc: 0.9792\n",
      "Batch 10/21 | Loss: 0.0384 | Acc: 0.9830\n",
      "Batch 15/21 | Loss: 0.0354 | Acc: 0.9844\n",
      "Batch 20/21 | Loss: 0.0341 | Acc: 0.9849\n",
      "Epoch 08 | Train Loss: 0.0341, Acc: 0.9849 | Val Loss: 0.2282, Acc: 0.9277, P: 0.9273, R: 0.9235, F1: 0.9253\n",
      "\n",
      "--- Epoch 9/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0243 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0252 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0399 | Acc: 0.9830\n",
      "Batch 15/21 | Loss: 0.0453 | Acc: 0.9766\n",
      "Batch 20/21 | Loss: 0.0464 | Acc: 0.9773\n",
      "Epoch 09 | Train Loss: 0.0464, Acc: 0.9773 | Val Loss: 0.3099, Acc: 0.9157, P: 0.9197, R: 0.9069, F1: 0.9120\n",
      "\n",
      "--- Epoch 10/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0200 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0349 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0253 | Acc: 0.9943\n",
      "Batch 15/21 | Loss: 0.0241 | Acc: 0.9961\n",
      "Batch 20/21 | Loss: 0.0292 | Acc: 0.9894\n",
      "Epoch 10 | Train Loss: 0.0292, Acc: 0.9894 | Val Loss: 0.3410, Acc: 0.9036, P: 0.9069, R: 0.8945, F1: 0.8994\n",
      "\n",
      "--- Epoch 11/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0431 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0283 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0286 | Acc: 0.9886\n",
      "Batch 15/21 | Loss: 0.0343 | Acc: 0.9902\n",
      "Batch 20/21 | Loss: 0.0289 | Acc: 0.9924\n",
      "Epoch 11 | Train Loss: 0.0289, Acc: 0.9924 | Val Loss: 0.2918, Acc: 0.9036, P: 0.9101, R: 0.8924, F1: 0.8989\n",
      "\n",
      "--- Epoch 12/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0034 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0490 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0416 | Acc: 0.9858\n",
      "Batch 15/21 | Loss: 0.0374 | Acc: 0.9863\n",
      "Batch 20/21 | Loss: 0.0342 | Acc: 0.9864\n",
      "Epoch 12 | Train Loss: 0.0342, Acc: 0.9864 | Val Loss: 0.2592, Acc: 0.9157, P: 0.9115, R: 0.9174, F1: 0.9139\n",
      "\n",
      "--- Epoch 13/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0077 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0295 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0244 | Acc: 0.9886\n",
      "Batch 15/21 | Loss: 0.0384 | Acc: 0.9863\n",
      "Batch 20/21 | Loss: 0.0413 | Acc: 0.9849\n",
      "Epoch 13 | Train Loss: 0.0413, Acc: 0.9849 | Val Loss: 0.4975, Acc: 0.8795, P: 0.9015, R: 0.8593, F1: 0.8704\n",
      "\n",
      "--- Epoch 14/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0143 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0184 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0329 | Acc: 0.9915\n",
      "Batch 15/21 | Loss: 0.0335 | Acc: 0.9902\n",
      "Batch 20/21 | Loss: 0.0340 | Acc: 0.9894\n",
      "Epoch 14 | Train Loss: 0.0340, Acc: 0.9894 | Val Loss: 0.3808, Acc: 0.9036, P: 0.9182, R: 0.8882, F1: 0.8977\n",
      "\n",
      "--- Epoch 15/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1400 | Acc: 0.9375\n",
      "Batch 5/21 | Loss: 0.0482 | Acc: 0.9740\n",
      "Batch 10/21 | Loss: 0.0461 | Acc: 0.9773\n",
      "Batch 15/21 | Loss: 0.0647 | Acc: 0.9766\n",
      "Batch 20/21 | Loss: 0.0567 | Acc: 0.9804\n",
      "Epoch 15 | Train Loss: 0.0567, Acc: 0.9804 | Val Loss: 0.2698, Acc: 0.9337, P: 0.9296, R: 0.9370, F1: 0.9324\n",
      "\n",
      "--- Epoch 16/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0492 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0152 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0162 | Acc: 0.9972\n",
      "Batch 15/21 | Loss: 0.0186 | Acc: 0.9961\n",
      "Batch 20/21 | Loss: 0.0280 | Acc: 0.9894\n",
      "Epoch 16 | Train Loss: 0.0280, Acc: 0.9894 | Val Loss: 0.4210, Acc: 0.9096, P: 0.9226, R: 0.8955, F1: 0.9044\n",
      "\n",
      "--- Epoch 17/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0018 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0825 | Acc: 0.9740\n",
      "Batch 10/21 | Loss: 0.0564 | Acc: 0.9830\n",
      "Batch 15/21 | Loss: 0.0458 | Acc: 0.9863\n",
      "Batch 20/21 | Loss: 0.0387 | Acc: 0.9879\n",
      "Epoch 17 | Train Loss: 0.0387, Acc: 0.9879 | Val Loss: 0.3251, Acc: 0.8976, P: 0.9020, R: 0.8873, F1: 0.8928\n",
      "\n",
      "--- Epoch 18/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0062 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0128 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0125 | Acc: 0.9972\n",
      "Batch 15/21 | Loss: 0.0149 | Acc: 0.9961\n",
      "Batch 20/21 | Loss: 0.0125 | Acc: 0.9970\n",
      "Epoch 18 | Train Loss: 0.0125, Acc: 0.9970 | Val Loss: 0.2968, Acc: 0.9277, P: 0.9273, R: 0.9235, F1: 0.9253\n",
      "\n",
      "--- Epoch 19/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0680 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0267 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0155 | Acc: 0.9915\n",
      "Batch 15/21 | Loss: 0.0145 | Acc: 0.9922\n",
      "Batch 20/21 | Loss: 0.0135 | Acc: 0.9924\n",
      "Epoch 19 | Train Loss: 0.0135, Acc: 0.9924 | Val Loss: 0.2988, Acc: 0.9458, P: 0.9435, R: 0.9452, F1: 0.9443\n",
      "\n",
      "--- Epoch 20/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0010 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0039 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0056 | Acc: 0.9972\n",
      "Batch 15/21 | Loss: 0.0086 | Acc: 0.9961\n",
      "Batch 20/21 | Loss: 0.0074 | Acc: 0.9970\n",
      "Epoch 20 | Train Loss: 0.0074, Acc: 0.9970 | Val Loss: 0.2827, Acc: 0.9458, P: 0.9435, R: 0.9452, F1: 0.9443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_state_ft, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Fold 3/5 ‚Äî convnext_tiny ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cauba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cauba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if use_amp else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñ∂Ô∏è Phase: fold3_frozen | epochs=10 | lr=0.001 | weight_decay=0.0001\n",
      "\n",
      "--- Epoch 1/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.7025 | Acc: 0.5625\n",
      "Batch 5/21 | Loss: 0.6713 | Acc: 0.5990\n",
      "Batch 10/21 | Loss: 0.6231 | Acc: 0.6477\n",
      "Batch 15/21 | Loss: 0.5773 | Acc: 0.7012\n",
      "Batch 20/21 | Loss: 0.5477 | Acc: 0.7341\n",
      "Epoch 01 | Train Loss: 0.5477, Acc: 0.7341 | Val Loss: 0.3984, Acc: 0.8494, P: 0.8454, R: 0.8439, F1: 0.8447\n",
      "\n",
      "--- Epoch 2/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3267 | Acc: 0.9062\n",
      "Batch 5/21 | Loss: 0.3972 | Acc: 0.8385\n",
      "Batch 10/21 | Loss: 0.3877 | Acc: 0.8466\n",
      "Batch 15/21 | Loss: 0.3822 | Acc: 0.8496\n",
      "Batch 20/21 | Loss: 0.3810 | Acc: 0.8520\n",
      "Epoch 02 | Train Loss: 0.3810, Acc: 0.8520 | Val Loss: 0.3430, Acc: 0.8494, P: 0.8443, R: 0.8481, F1: 0.8459\n",
      "\n",
      "--- Epoch 3/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3146 | Acc: 0.8750\n",
      "Batch 5/21 | Loss: 0.3439 | Acc: 0.8854\n",
      "Batch 10/21 | Loss: 0.3431 | Acc: 0.8778\n",
      "Batch 15/21 | Loss: 0.3309 | Acc: 0.8828\n",
      "Batch 20/21 | Loss: 0.3276 | Acc: 0.8776\n",
      "Epoch 03 | Train Loss: 0.3276, Acc: 0.8776 | Val Loss: 0.3217, Acc: 0.8675, P: 0.8685, R: 0.8573, F1: 0.8617\n",
      "\n",
      "--- Epoch 4/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.4022 | Acc: 0.8750\n",
      "Batch 5/21 | Loss: 0.3128 | Acc: 0.8854\n",
      "Batch 10/21 | Loss: 0.2889 | Acc: 0.8977\n",
      "Batch 15/21 | Loss: 0.2839 | Acc: 0.9023\n",
      "Batch 20/21 | Loss: 0.2817 | Acc: 0.9018\n",
      "Epoch 04 | Train Loss: 0.2817, Acc: 0.9018 | Val Loss: 0.3064, Acc: 0.8614, P: 0.8634, R: 0.8501, F1: 0.8550\n",
      "\n",
      "--- Epoch 5/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.4110 | Acc: 0.8438\n",
      "Batch 5/21 | Loss: 0.2991 | Acc: 0.8646\n",
      "Batch 10/21 | Loss: 0.2763 | Acc: 0.8778\n",
      "Batch 15/21 | Loss: 0.2893 | Acc: 0.8730\n",
      "Batch 20/21 | Loss: 0.2831 | Acc: 0.8807\n",
      "Epoch 05 | Train Loss: 0.2831, Acc: 0.8807 | Val Loss: 0.3003, Acc: 0.8735, P: 0.8738, R: 0.8646, F1: 0.8683\n",
      "\n",
      "--- Epoch 6/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3713 | Acc: 0.8750\n",
      "Batch 5/21 | Loss: 0.2658 | Acc: 0.9010\n",
      "Batch 10/21 | Loss: 0.2542 | Acc: 0.9034\n",
      "Batch 15/21 | Loss: 0.2530 | Acc: 0.9082\n",
      "Batch 20/21 | Loss: 0.2672 | Acc: 0.8973\n",
      "Epoch 06 | Train Loss: 0.2672, Acc: 0.8973 | Val Loss: 0.2928, Acc: 0.8735, P: 0.8718, R: 0.8667, F1: 0.8689\n",
      "\n",
      "--- Epoch 7/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2830 | Acc: 0.8438\n",
      "Batch 5/21 | Loss: 0.3072 | Acc: 0.8646\n",
      "Batch 10/21 | Loss: 0.2792 | Acc: 0.8920\n",
      "Batch 15/21 | Loss: 0.2712 | Acc: 0.8984\n",
      "Batch 20/21 | Loss: 0.2649 | Acc: 0.9033\n",
      "Epoch 07 | Train Loss: 0.2649, Acc: 0.9033 | Val Loss: 0.2987, Acc: 0.8795, P: 0.8791, R: 0.8718, F1: 0.8749\n",
      "\n",
      "--- Epoch 8/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.4000 | Acc: 0.8125\n",
      "Batch 5/21 | Loss: 0.2643 | Acc: 0.8906\n",
      "Batch 10/21 | Loss: 0.2487 | Acc: 0.9062\n",
      "Batch 15/21 | Loss: 0.2491 | Acc: 0.9062\n",
      "Batch 20/21 | Loss: 0.2414 | Acc: 0.9079\n",
      "Epoch 08 | Train Loss: 0.2414, Acc: 0.9079 | Val Loss: 0.2935, Acc: 0.8795, P: 0.8791, R: 0.8718, F1: 0.8749\n",
      "\n",
      "--- Epoch 9/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1624 | Acc: 0.9062\n",
      "Batch 5/21 | Loss: 0.2517 | Acc: 0.9115\n",
      "Batch 10/21 | Loss: 0.2113 | Acc: 0.9347\n",
      "Batch 15/21 | Loss: 0.2199 | Acc: 0.9297\n",
      "Batch 20/21 | Loss: 0.2329 | Acc: 0.9199\n",
      "Epoch 09 | Train Loss: 0.2329, Acc: 0.9199 | Val Loss: 0.2946, Acc: 0.8855, P: 0.8817, R: 0.8832, F1: 0.8824\n",
      "\n",
      "--- Epoch 10/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2231 | Acc: 0.9375\n",
      "Batch 5/21 | Loss: 0.2096 | Acc: 0.9062\n",
      "Batch 10/21 | Loss: 0.2365 | Acc: 0.9006\n",
      "Batch 15/21 | Loss: 0.2330 | Acc: 0.9023\n",
      "Batch 20/21 | Loss: 0.2308 | Acc: 0.9048\n",
      "Epoch 10 | Train Loss: 0.2308, Acc: 0.9048 | Val Loss: 0.2843, Acc: 0.8976, P: 0.8940, R: 0.8956, F1: 0.8948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_state_frozen, map_location=device))\n",
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if use_amp else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñ∂Ô∏è Phase: fold3_finetune | epochs=20 | lr=0.0001 | weight_decay=0.0001\n",
      "\n",
      "--- Epoch 1/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1901 | Acc: 0.9375\n",
      "Batch 5/21 | Loss: 0.6239 | Acc: 0.7760\n",
      "Batch 10/21 | Loss: 0.6636 | Acc: 0.7699\n",
      "Batch 15/21 | Loss: 0.5758 | Acc: 0.8008\n",
      "Batch 20/21 | Loss: 0.5287 | Acc: 0.8082\n",
      "Epoch 01 | Train Loss: 0.5287, Acc: 0.8082 | Val Loss: 0.3148, Acc: 0.8735, P: 0.8738, R: 0.8646, F1: 0.8683\n",
      "\n",
      "--- Epoch 2/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2510 | Acc: 0.9375\n",
      "Batch 5/21 | Loss: 0.2672 | Acc: 0.8854\n",
      "Batch 10/21 | Loss: 0.2180 | Acc: 0.9148\n",
      "Batch 15/21 | Loss: 0.2422 | Acc: 0.9004\n",
      "Batch 20/21 | Loss: 0.2160 | Acc: 0.9094\n",
      "Epoch 02 | Train Loss: 0.2160, Acc: 0.9094 | Val Loss: 0.3314, Acc: 0.8675, P: 0.8643, R: 0.8740, F1: 0.8659\n",
      "\n",
      "--- Epoch 3/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0562 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.1790 | Acc: 0.9271\n",
      "Batch 10/21 | Loss: 0.1684 | Acc: 0.9318\n",
      "Batch 15/21 | Loss: 0.1614 | Acc: 0.9414\n",
      "Batch 20/21 | Loss: 0.1679 | Acc: 0.9396\n",
      "Epoch 03 | Train Loss: 0.1679, Acc: 0.9396 | Val Loss: 0.2488, Acc: 0.9217, P: 0.9221, R: 0.9163, F1: 0.9189\n",
      "\n",
      "--- Epoch 4/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1282 | Acc: 0.9375\n",
      "Batch 5/21 | Loss: 0.1223 | Acc: 0.9479\n",
      "Batch 10/21 | Loss: 0.1067 | Acc: 0.9545\n",
      "Batch 15/21 | Loss: 0.1024 | Acc: 0.9590\n",
      "Batch 20/21 | Loss: 0.1062 | Acc: 0.9577\n",
      "Epoch 04 | Train Loss: 0.1062, Acc: 0.9577 | Val Loss: 0.2922, Acc: 0.9217, P: 0.9187, R: 0.9204, F1: 0.9196\n",
      "\n",
      "--- Epoch 5/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0455 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0587 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0805 | Acc: 0.9773\n",
      "Batch 15/21 | Loss: 0.0827 | Acc: 0.9746\n",
      "Batch 20/21 | Loss: 0.0885 | Acc: 0.9713\n",
      "Epoch 05 | Train Loss: 0.0885, Acc: 0.9713 | Val Loss: 0.3230, Acc: 0.9036, P: 0.8998, R: 0.9029, F1: 0.9012\n",
      "\n",
      "--- Epoch 6/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0550 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0608 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0800 | Acc: 0.9773\n",
      "Batch 15/21 | Loss: 0.0678 | Acc: 0.9805\n",
      "Batch 20/21 | Loss: 0.0789 | Acc: 0.9743\n",
      "Epoch 06 | Train Loss: 0.0789, Acc: 0.9743 | Val Loss: 0.3456, Acc: 0.8855, P: 0.9005, R: 0.8686, F1: 0.8781\n",
      "\n",
      "--- Epoch 7/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0816 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0616 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0480 | Acc: 0.9886\n",
      "Batch 15/21 | Loss: 0.0396 | Acc: 0.9922\n",
      "Batch 20/21 | Loss: 0.0351 | Acc: 0.9940\n",
      "Epoch 07 | Train Loss: 0.0351, Acc: 0.9940 | Val Loss: 0.2992, Acc: 0.9157, P: 0.9115, R: 0.9174, F1: 0.9139\n",
      "\n",
      "--- Epoch 8/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0148 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0193 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0197 | Acc: 0.9972\n",
      "Batch 15/21 | Loss: 0.0275 | Acc: 0.9941\n",
      "Batch 20/21 | Loss: 0.0282 | Acc: 0.9924\n",
      "Epoch 08 | Train Loss: 0.0282, Acc: 0.9924 | Val Loss: 0.2871, Acc: 0.8976, P: 0.8931, R: 0.8998, F1: 0.8956\n",
      "\n",
      "--- Epoch 9/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0708 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0228 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0343 | Acc: 0.9858\n",
      "Batch 15/21 | Loss: 0.0298 | Acc: 0.9883\n",
      "Batch 20/21 | Loss: 0.0277 | Acc: 0.9909\n",
      "Epoch 09 | Train Loss: 0.0277, Acc: 0.9909 | Val Loss: 0.3113, Acc: 0.9096, P: 0.9077, R: 0.9059, F1: 0.9068\n",
      "\n",
      "--- Epoch 10/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0165 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0355 | Acc: 0.9792\n",
      "Batch 10/21 | Loss: 0.0260 | Acc: 0.9858\n",
      "Batch 15/21 | Loss: 0.0211 | Acc: 0.9902\n",
      "Batch 20/21 | Loss: 0.0310 | Acc: 0.9879\n",
      "Epoch 10 | Train Loss: 0.0310, Acc: 0.9879 | Val Loss: 0.4284, Acc: 0.8976, P: 0.8939, R: 0.9040, F1: 0.8962\n",
      "\n",
      "--- Epoch 11/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0977 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0450 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0555 | Acc: 0.9801\n",
      "Batch 15/21 | Loss: 0.0522 | Acc: 0.9785\n",
      "Batch 20/21 | Loss: 0.0530 | Acc: 0.9819\n",
      "Epoch 11 | Train Loss: 0.0530, Acc: 0.9819 | Val Loss: 0.2591, Acc: 0.9217, P: 0.9221, R: 0.9163, F1: 0.9189\n",
      "\n",
      "--- Epoch 12/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0051 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0482 | Acc: 0.9792\n",
      "Batch 10/21 | Loss: 0.0365 | Acc: 0.9858\n",
      "Batch 15/21 | Loss: 0.0356 | Acc: 0.9883\n",
      "Batch 20/21 | Loss: 0.0339 | Acc: 0.9894\n",
      "Epoch 12 | Train Loss: 0.0339, Acc: 0.9894 | Val Loss: 0.3774, Acc: 0.9096, P: 0.9054, R: 0.9143, F1: 0.9082\n",
      "\n",
      "--- Epoch 13/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0117 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0208 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0214 | Acc: 0.9915\n",
      "Batch 15/21 | Loss: 0.0287 | Acc: 0.9883\n",
      "Batch 20/21 | Loss: 0.0275 | Acc: 0.9879\n",
      "Epoch 13 | Train Loss: 0.0275, Acc: 0.9879 | Val Loss: 0.3412, Acc: 0.9217, P: 0.9178, R: 0.9225, F1: 0.9199\n",
      "\n",
      "--- Epoch 14/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0093 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0196 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0214 | Acc: 0.9972\n",
      "Batch 15/21 | Loss: 0.0235 | Acc: 0.9941\n",
      "Batch 20/21 | Loss: 0.0231 | Acc: 0.9924\n",
      "Epoch 14 | Train Loss: 0.0231, Acc: 0.9924 | Val Loss: 0.3937, Acc: 0.9096, P: 0.9149, R: 0.8997, F1: 0.9054\n",
      "\n",
      "--- Epoch 15/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0030 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0058 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0107 | Acc: 0.9972\n",
      "Batch 15/21 | Loss: 0.0107 | Acc: 0.9980\n",
      "Batch 20/21 | Loss: 0.0108 | Acc: 0.9985\n",
      "Epoch 15 | Train Loss: 0.0108, Acc: 0.9985 | Val Loss: 0.3465, Acc: 0.9157, P: 0.9132, R: 0.9132, F1: 0.9132\n",
      "\n",
      "--- Epoch 16/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0017 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0118 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0128 | Acc: 0.9943\n",
      "Batch 15/21 | Loss: 0.0232 | Acc: 0.9902\n",
      "Batch 20/21 | Loss: 0.0269 | Acc: 0.9879\n",
      "Epoch 16 | Train Loss: 0.0269, Acc: 0.9879 | Val Loss: 0.3042, Acc: 0.9277, P: 0.9256, R: 0.9256, F1: 0.9256\n",
      "\n",
      "--- Epoch 17/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0018 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0123 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0133 | Acc: 1.0000\n",
      "Batch 15/21 | Loss: 0.0256 | Acc: 0.9902\n",
      "Batch 20/21 | Loss: 0.0306 | Acc: 0.9879\n",
      "Epoch 17 | Train Loss: 0.0306, Acc: 0.9879 | Val Loss: 0.3499, Acc: 0.9157, P: 0.9148, R: 0.9111, F1: 0.9128\n",
      "\n",
      "--- Epoch 18/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0014 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0114 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0433 | Acc: 0.9801\n",
      "Batch 15/21 | Loss: 0.0421 | Acc: 0.9824\n",
      "Batch 20/21 | Loss: 0.0402 | Acc: 0.9819\n",
      "Epoch 18 | Train Loss: 0.0402, Acc: 0.9819 | Val Loss: 0.4297, Acc: 0.8976, P: 0.8933, R: 0.9019, F1: 0.8959\n",
      "\n",
      "--- Epoch 19/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0196 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0164 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0225 | Acc: 0.9915\n",
      "Batch 15/21 | Loss: 0.0199 | Acc: 0.9922\n",
      "Batch 20/21 | Loss: 0.0215 | Acc: 0.9909\n",
      "Epoch 19 | Train Loss: 0.0215, Acc: 0.9909 | Val Loss: 0.3077, Acc: 0.9217, P: 0.9246, R: 0.9142, F1: 0.9185\n",
      "\n",
      "--- Epoch 20/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0156 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0135 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0138 | Acc: 0.9943\n",
      "Batch 15/21 | Loss: 0.0165 | Acc: 0.9941\n",
      "Batch 20/21 | Loss: 0.0194 | Acc: 0.9909\n",
      "Epoch 20 | Train Loss: 0.0194, Acc: 0.9909 | Val Loss: 0.2731, Acc: 0.9217, P: 0.9175, R: 0.9267, F1: 0.9204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_state_ft, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Fold 4/5 ‚Äî convnext_tiny ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cauba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cauba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if use_amp else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñ∂Ô∏è Phase: fold4_frozen | epochs=10 | lr=0.001 | weight_decay=0.0001\n",
      "\n",
      "--- Epoch 1/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.8370 | Acc: 0.2812\n",
      "Batch 5/21 | Loss: 0.6882 | Acc: 0.5000\n",
      "Batch 10/21 | Loss: 0.6274 | Acc: 0.5966\n",
      "Batch 15/21 | Loss: 0.5900 | Acc: 0.6426\n",
      "Batch 20/21 | Loss: 0.5641 | Acc: 0.6712\n",
      "Epoch 01 | Train Loss: 0.5641, Acc: 0.6712 | Val Loss: 0.4117, Acc: 0.8364, P: 0.8368, R: 0.8247, F1: 0.8291\n",
      "\n",
      "--- Epoch 2/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.4409 | Acc: 0.7812\n",
      "Batch 5/21 | Loss: 0.4449 | Acc: 0.7969\n",
      "Batch 10/21 | Loss: 0.4338 | Acc: 0.8068\n",
      "Batch 15/21 | Loss: 0.4118 | Acc: 0.8262\n",
      "Batch 20/21 | Loss: 0.4005 | Acc: 0.8341\n",
      "Epoch 02 | Train Loss: 0.4005, Acc: 0.8341 | Val Loss: 0.3440, Acc: 0.8970, P: 0.9014, R: 0.8870, F1: 0.8924\n",
      "\n",
      "--- Epoch 3/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3155 | Acc: 0.9375\n",
      "Batch 5/21 | Loss: 0.3342 | Acc: 0.8750\n",
      "Batch 10/21 | Loss: 0.3603 | Acc: 0.8523\n",
      "Batch 15/21 | Loss: 0.3513 | Acc: 0.8535\n",
      "Batch 20/21 | Loss: 0.3437 | Acc: 0.8567\n",
      "Epoch 03 | Train Loss: 0.3437, Acc: 0.8567 | Val Loss: 0.3115, Acc: 0.8848, P: 0.8859, R: 0.8766, F1: 0.8803\n",
      "\n",
      "--- Epoch 4/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3565 | Acc: 0.9062\n",
      "Batch 5/21 | Loss: 0.3163 | Acc: 0.8906\n",
      "Batch 10/21 | Loss: 0.2917 | Acc: 0.8949\n",
      "Batch 15/21 | Loss: 0.3055 | Acc: 0.8809\n",
      "Batch 20/21 | Loss: 0.2997 | Acc: 0.8914\n",
      "Epoch 04 | Train Loss: 0.2997, Acc: 0.8914 | Val Loss: 0.2911, Acc: 0.9152, P: 0.9128, R: 0.9128, F1: 0.9128\n",
      "\n",
      "--- Epoch 5/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2492 | Acc: 0.9062\n",
      "Batch 5/21 | Loss: 0.3097 | Acc: 0.8750\n",
      "Batch 10/21 | Loss: 0.2726 | Acc: 0.8977\n",
      "Batch 15/21 | Loss: 0.2881 | Acc: 0.8848\n",
      "Batch 20/21 | Loss: 0.3009 | Acc: 0.8793\n",
      "Epoch 05 | Train Loss: 0.3009, Acc: 0.8793 | Val Loss: 0.2795, Acc: 0.8848, P: 0.8917, R: 0.8725, F1: 0.8791\n",
      "\n",
      "--- Epoch 6/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2737 | Acc: 0.8438\n",
      "Batch 5/21 | Loss: 0.2525 | Acc: 0.8854\n",
      "Batch 10/21 | Loss: 0.2751 | Acc: 0.8722\n",
      "Batch 15/21 | Loss: 0.2724 | Acc: 0.8828\n",
      "Batch 20/21 | Loss: 0.2776 | Acc: 0.8778\n",
      "Epoch 06 | Train Loss: 0.2776, Acc: 0.8778 | Val Loss: 0.2564, Acc: 0.8970, P: 0.8965, R: 0.8911, F1: 0.8934\n",
      "\n",
      "--- Epoch 7/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.4037 | Acc: 0.8438\n",
      "Batch 5/21 | Loss: 0.2519 | Acc: 0.9271\n",
      "Batch 10/21 | Loss: 0.2535 | Acc: 0.9176\n",
      "Batch 15/21 | Loss: 0.2690 | Acc: 0.9062\n",
      "Batch 20/21 | Loss: 0.2768 | Acc: 0.8974\n",
      "Epoch 07 | Train Loss: 0.2768, Acc: 0.8974 | Val Loss: 0.2525, Acc: 0.8848, P: 0.8917, R: 0.8725, F1: 0.8791\n",
      "\n",
      "--- Epoch 8/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3647 | Acc: 0.9062\n",
      "Batch 5/21 | Loss: 0.2519 | Acc: 0.9062\n",
      "Batch 10/21 | Loss: 0.2435 | Acc: 0.9091\n",
      "Batch 15/21 | Loss: 0.2577 | Acc: 0.8984\n",
      "Batch 20/21 | Loss: 0.2533 | Acc: 0.8989\n",
      "Epoch 08 | Train Loss: 0.2533, Acc: 0.8989 | Val Loss: 0.2427, Acc: 0.8970, P: 0.8987, R: 0.8890, F1: 0.8929\n",
      "\n",
      "--- Epoch 9/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1636 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.2434 | Acc: 0.9167\n",
      "Batch 10/21 | Loss: 0.2227 | Acc: 0.9261\n",
      "Batch 15/21 | Loss: 0.2415 | Acc: 0.9160\n",
      "Batch 20/21 | Loss: 0.2433 | Acc: 0.9125\n",
      "Epoch 09 | Train Loss: 0.2433, Acc: 0.9125 | Val Loss: 0.2525, Acc: 0.8788, P: 0.8835, R: 0.8673, F1: 0.8731\n",
      "\n",
      "--- Epoch 10/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1856 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.2092 | Acc: 0.9427\n",
      "Batch 10/21 | Loss: 0.2274 | Acc: 0.9176\n",
      "Batch 15/21 | Loss: 0.2497 | Acc: 0.9004\n",
      "Batch 20/21 | Loss: 0.2466 | Acc: 0.8989\n",
      "Epoch 10 | Train Loss: 0.2466, Acc: 0.8989 | Val Loss: 0.2472, Acc: 0.8788, P: 0.8835, R: 0.8673, F1: 0.8731\n",
      "\n",
      "‚ñ∂Ô∏è Phase: fold4_finetune | epochs=20 | lr=0.0001 | weight_decay=0.0001\n",
      "\n",
      "--- Epoch 1/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_state_frozen, map_location=device))\n",
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if use_amp else None\n",
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3459 | Acc: 0.8125\n",
      "Batch 5/21 | Loss: 0.3168 | Acc: 0.8698\n",
      "Batch 10/21 | Loss: 0.3252 | Acc: 0.8693\n",
      "Batch 15/21 | Loss: 0.3058 | Acc: 0.8809\n",
      "Batch 20/21 | Loss: 0.3031 | Acc: 0.8793\n",
      "Epoch 01 | Train Loss: 0.3031, Acc: 0.8793 | Val Loss: 0.3685, Acc: 0.8364, P: 0.8732, R: 0.8084, F1: 0.8198\n",
      "\n",
      "--- Epoch 2/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2396 | Acc: 0.9062\n",
      "Batch 5/21 | Loss: 0.2246 | Acc: 0.8854\n",
      "Batch 10/21 | Loss: 0.2100 | Acc: 0.9091\n",
      "Batch 15/21 | Loss: 0.2057 | Acc: 0.9082\n",
      "Batch 20/21 | Loss: 0.1969 | Acc: 0.9186\n",
      "Epoch 02 | Train Loss: 0.1969, Acc: 0.9186 | Val Loss: 0.1983, Acc: 0.9212, P: 0.9184, R: 0.9201, F1: 0.9192\n",
      "\n",
      "--- Epoch 3/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0749 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.1580 | Acc: 0.9479\n",
      "Batch 10/21 | Loss: 0.1391 | Acc: 0.9489\n",
      "Batch 15/21 | Loss: 0.1287 | Acc: 0.9570\n",
      "Batch 20/21 | Loss: 0.1318 | Acc: 0.9502\n",
      "Epoch 03 | Train Loss: 0.1318, Acc: 0.9502 | Val Loss: 0.2034, Acc: 0.9333, P: 0.9295, R: 0.9366, F1: 0.9321\n",
      "\n",
      "--- Epoch 4/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1801 | Acc: 0.9375\n",
      "Batch 5/21 | Loss: 0.1368 | Acc: 0.9583\n",
      "Batch 10/21 | Loss: 0.1405 | Acc: 0.9460\n",
      "Batch 15/21 | Loss: 0.1190 | Acc: 0.9531\n",
      "Batch 20/21 | Loss: 0.1135 | Acc: 0.9578\n",
      "Epoch 04 | Train Loss: 0.1135, Acc: 0.9578 | Val Loss: 0.2917, Acc: 0.9030, P: 0.9176, R: 0.8881, F1: 0.8973\n",
      "\n",
      "--- Epoch 5/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1790 | Acc: 0.9375\n",
      "Batch 5/21 | Loss: 0.0960 | Acc: 0.9635\n",
      "Batch 10/21 | Loss: 0.0862 | Acc: 0.9688\n",
      "Batch 15/21 | Loss: 0.0844 | Acc: 0.9688\n",
      "Batch 20/21 | Loss: 0.0987 | Acc: 0.9638\n",
      "Epoch 05 | Train Loss: 0.0987, Acc: 0.9638 | Val Loss: 0.2314, Acc: 0.9152, P: 0.9128, R: 0.9128, F1: 0.9128\n",
      "\n",
      "--- Epoch 6/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1383 | Acc: 0.9375\n",
      "Batch 5/21 | Loss: 0.0815 | Acc: 0.9740\n",
      "Batch 10/21 | Loss: 0.0636 | Acc: 0.9830\n",
      "Batch 15/21 | Loss: 0.0588 | Acc: 0.9824\n",
      "Batch 20/21 | Loss: 0.0528 | Acc: 0.9849\n",
      "Epoch 06 | Train Loss: 0.0528, Acc: 0.9849 | Val Loss: 0.2316, Acc: 0.9152, P: 0.9128, R: 0.9128, F1: 0.9128\n",
      "\n",
      "--- Epoch 7/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0262 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0628 | Acc: 0.9740\n",
      "Batch 10/21 | Loss: 0.0560 | Acc: 0.9744\n",
      "Batch 15/21 | Loss: 0.0578 | Acc: 0.9746\n",
      "Batch 20/21 | Loss: 0.0568 | Acc: 0.9759\n",
      "Epoch 07 | Train Loss: 0.0568, Acc: 0.9759 | Val Loss: 0.2591, Acc: 0.8909, P: 0.8879, R: 0.8879, F1: 0.8879\n",
      "\n",
      "--- Epoch 8/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0761 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0450 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0294 | Acc: 0.9915\n",
      "Batch 15/21 | Loss: 0.0319 | Acc: 0.9922\n",
      "Batch 20/21 | Loss: 0.0468 | Acc: 0.9849\n",
      "Epoch 08 | Train Loss: 0.0468, Acc: 0.9849 | Val Loss: 0.2423, Acc: 0.9394, P: 0.9365, R: 0.9398, F1: 0.9380\n",
      "\n",
      "--- Epoch 9/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0181 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0291 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0497 | Acc: 0.9830\n",
      "Batch 15/21 | Loss: 0.0458 | Acc: 0.9824\n",
      "Batch 20/21 | Loss: 0.0653 | Acc: 0.9729\n",
      "Epoch 09 | Train Loss: 0.0653, Acc: 0.9729 | Val Loss: 0.2884, Acc: 0.9152, P: 0.9124, R: 0.9230, F1: 0.9142\n",
      "\n",
      "--- Epoch 10/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0378 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0294 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0347 | Acc: 0.9915\n",
      "Batch 15/21 | Loss: 0.0428 | Acc: 0.9824\n",
      "Batch 20/21 | Loss: 0.0393 | Acc: 0.9849\n",
      "Epoch 10 | Train Loss: 0.0393, Acc: 0.9849 | Val Loss: 0.3179, Acc: 0.9152, P: 0.9192, R: 0.9067, F1: 0.9116\n",
      "\n",
      "--- Epoch 11/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0235 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0168 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0161 | Acc: 0.9972\n",
      "Batch 15/21 | Loss: 0.0174 | Acc: 0.9961\n",
      "Batch 20/21 | Loss: 0.0261 | Acc: 0.9910\n",
      "Epoch 11 | Train Loss: 0.0261, Acc: 0.9910 | Val Loss: 0.2224, Acc: 0.9394, P: 0.9365, R: 0.9398, F1: 0.9380\n",
      "\n",
      "--- Epoch 12/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0064 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0169 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0214 | Acc: 0.9886\n",
      "Batch 15/21 | Loss: 0.0194 | Acc: 0.9922\n",
      "Batch 20/21 | Loss: 0.0176 | Acc: 0.9940\n",
      "Epoch 12 | Train Loss: 0.0176, Acc: 0.9940 | Val Loss: 0.3690, Acc: 0.9152, P: 0.9225, R: 0.9047, F1: 0.9112\n",
      "\n",
      "--- Epoch 13/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0064 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0404 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0314 | Acc: 0.9886\n",
      "Batch 15/21 | Loss: 0.0280 | Acc: 0.9902\n",
      "Batch 20/21 | Loss: 0.0328 | Acc: 0.9864\n",
      "Epoch 13 | Train Loss: 0.0328, Acc: 0.9864 | Val Loss: 0.2156, Acc: 0.9394, P: 0.9365, R: 0.9398, F1: 0.9380\n",
      "\n",
      "--- Epoch 14/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0039 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0150 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0131 | Acc: 0.9972\n",
      "Batch 15/21 | Loss: 0.0164 | Acc: 0.9961\n",
      "Batch 20/21 | Loss: 0.0170 | Acc: 0.9955\n",
      "Epoch 14 | Train Loss: 0.0170, Acc: 0.9955 | Val Loss: 0.2415, Acc: 0.9394, P: 0.9358, R: 0.9418, F1: 0.9382\n",
      "\n",
      "--- Epoch 15/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0147 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0185 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0285 | Acc: 0.9886\n",
      "Batch 15/21 | Loss: 0.0402 | Acc: 0.9902\n",
      "Batch 20/21 | Loss: 0.0333 | Acc: 0.9925\n",
      "Epoch 15 | Train Loss: 0.0333, Acc: 0.9925 | Val Loss: 0.2597, Acc: 0.9394, P: 0.9377, R: 0.9377, F1: 0.9377\n",
      "\n",
      "--- Epoch 16/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0030 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0200 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0177 | Acc: 0.9915\n",
      "Batch 15/21 | Loss: 0.0158 | Acc: 0.9922\n",
      "Batch 20/21 | Loss: 0.0157 | Acc: 0.9925\n",
      "Epoch 16 | Train Loss: 0.0157, Acc: 0.9925 | Val Loss: 0.2840, Acc: 0.9455, P: 0.9422, R: 0.9470, F1: 0.9443\n",
      "\n",
      "--- Epoch 17/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0023 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0052 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0065 | Acc: 1.0000\n",
      "Batch 15/21 | Loss: 0.0104 | Acc: 0.9980\n",
      "Batch 20/21 | Loss: 0.0104 | Acc: 0.9985\n",
      "Epoch 17 | Train Loss: 0.0104, Acc: 0.9985 | Val Loss: 0.2927, Acc: 0.9394, P: 0.9395, R: 0.9357, F1: 0.9375\n",
      "\n",
      "--- Epoch 18/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0032 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0071 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0113 | Acc: 0.9972\n",
      "Batch 15/21 | Loss: 0.0087 | Acc: 0.9980\n",
      "Batch 20/21 | Loss: 0.0080 | Acc: 0.9985\n",
      "Epoch 18 | Train Loss: 0.0080, Acc: 0.9985 | Val Loss: 0.2926, Acc: 0.9394, P: 0.9365, R: 0.9398, F1: 0.9380\n",
      "\n",
      "--- Epoch 19/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0079 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0049 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0068 | Acc: 1.0000\n",
      "Batch 15/21 | Loss: 0.0135 | Acc: 0.9980\n",
      "Batch 20/21 | Loss: 0.0153 | Acc: 0.9970\n",
      "Epoch 19 | Train Loss: 0.0153, Acc: 0.9970 | Val Loss: 0.2839, Acc: 0.9273, P: 0.9235, R: 0.9293, F1: 0.9258\n",
      "\n",
      "--- Epoch 20/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0093 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0444 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0263 | Acc: 0.9943\n",
      "Batch 15/21 | Loss: 0.0247 | Acc: 0.9922\n",
      "Batch 20/21 | Loss: 0.0201 | Acc: 0.9940\n",
      "Epoch 20 | Train Loss: 0.0201, Acc: 0.9940 | Val Loss: 0.3056, Acc: 0.9394, P: 0.9395, R: 0.9357, F1: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_state_ft, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Fold 5/5 ‚Äî convnext_tiny ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cauba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cauba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if use_amp else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñ∂Ô∏è Phase: fold5_frozen | epochs=10 | lr=0.001 | weight_decay=0.0001\n",
      "\n",
      "--- Epoch 1/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.8953 | Acc: 0.3750\n",
      "Batch 5/21 | Loss: 0.7393 | Acc: 0.5000\n",
      "Batch 10/21 | Loss: 0.6707 | Acc: 0.5795\n",
      "Batch 15/21 | Loss: 0.6306 | Acc: 0.6230\n",
      "Batch 20/21 | Loss: 0.5992 | Acc: 0.6546\n",
      "Epoch 01 | Train Loss: 0.5992, Acc: 0.6546 | Val Loss: 0.4360, Acc: 0.8121, P: 0.8223, R: 0.7917, F1: 0.7991\n",
      "\n",
      "--- Epoch 2/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.4852 | Acc: 0.8125\n",
      "Batch 5/21 | Loss: 0.4266 | Acc: 0.8229\n",
      "Batch 10/21 | Loss: 0.4231 | Acc: 0.8153\n",
      "Batch 15/21 | Loss: 0.4284 | Acc: 0.8125\n",
      "Batch 20/21 | Loss: 0.4084 | Acc: 0.8281\n",
      "Epoch 02 | Train Loss: 0.4084, Acc: 0.8281 | Val Loss: 0.3552, Acc: 0.8545, P: 0.8531, R: 0.8465, F1: 0.8492\n",
      "\n",
      "--- Epoch 3/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3450 | Acc: 0.8125\n",
      "Batch 5/21 | Loss: 0.3888 | Acc: 0.8177\n",
      "Batch 10/21 | Loss: 0.3856 | Acc: 0.8182\n",
      "Batch 15/21 | Loss: 0.3528 | Acc: 0.8418\n",
      "Batch 20/21 | Loss: 0.3645 | Acc: 0.8371\n",
      "Epoch 03 | Train Loss: 0.3645, Acc: 0.8371 | Val Loss: 0.3234, Acc: 0.8727, P: 0.8756, R: 0.8621, F1: 0.8671\n",
      "\n",
      "--- Epoch 4/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2347 | Acc: 0.9375\n",
      "Batch 5/21 | Loss: 0.3028 | Acc: 0.9010\n",
      "Batch 10/21 | Loss: 0.3057 | Acc: 0.8722\n",
      "Batch 15/21 | Loss: 0.2922 | Acc: 0.8828\n",
      "Batch 20/21 | Loss: 0.3103 | Acc: 0.8718\n",
      "Epoch 04 | Train Loss: 0.3103, Acc: 0.8718 | Val Loss: 0.3036, Acc: 0.8909, P: 0.8893, R: 0.8859, F1: 0.8874\n",
      "\n",
      "--- Epoch 5/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1591 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.2913 | Acc: 0.8906\n",
      "Batch 10/21 | Loss: 0.2803 | Acc: 0.8778\n",
      "Batch 15/21 | Loss: 0.2808 | Acc: 0.8789\n",
      "Batch 20/21 | Loss: 0.2876 | Acc: 0.8763\n",
      "Epoch 05 | Train Loss: 0.2876, Acc: 0.8763 | Val Loss: 0.2912, Acc: 0.8848, P: 0.8838, R: 0.8786, F1: 0.8809\n",
      "\n",
      "--- Epoch 6/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2915 | Acc: 0.8750\n",
      "Batch 5/21 | Loss: 0.3105 | Acc: 0.8646\n",
      "Batch 10/21 | Loss: 0.3065 | Acc: 0.8693\n",
      "Batch 15/21 | Loss: 0.2967 | Acc: 0.8750\n",
      "Batch 20/21 | Loss: 0.2837 | Acc: 0.8854\n",
      "Epoch 06 | Train Loss: 0.2837, Acc: 0.8854 | Val Loss: 0.2941, Acc: 0.8909, P: 0.9001, R: 0.8777, F1: 0.8851\n",
      "\n",
      "--- Epoch 7/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2392 | Acc: 0.8750\n",
      "Batch 5/21 | Loss: 0.3039 | Acc: 0.8594\n",
      "Batch 10/21 | Loss: 0.2882 | Acc: 0.8778\n",
      "Batch 15/21 | Loss: 0.2784 | Acc: 0.8848\n",
      "Batch 20/21 | Loss: 0.2762 | Acc: 0.8839\n",
      "Epoch 07 | Train Loss: 0.2762, Acc: 0.8839 | Val Loss: 0.2799, Acc: 0.9030, P: 0.9064, R: 0.8942, F1: 0.8990\n",
      "\n",
      "--- Epoch 8/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2734 | Acc: 0.8750\n",
      "Batch 5/21 | Loss: 0.3043 | Acc: 0.8750\n",
      "Batch 10/21 | Loss: 0.2855 | Acc: 0.8949\n",
      "Batch 15/21 | Loss: 0.2741 | Acc: 0.8906\n",
      "Batch 20/21 | Loss: 0.2688 | Acc: 0.8884\n",
      "Epoch 08 | Train Loss: 0.2688, Acc: 0.8884 | Val Loss: 0.2715, Acc: 0.9030, P: 0.9018, R: 0.8983, F1: 0.8999\n",
      "\n",
      "--- Epoch 9/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.2115 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.2393 | Acc: 0.8958\n",
      "Batch 10/21 | Loss: 0.2589 | Acc: 0.8750\n",
      "Batch 15/21 | Loss: 0.2493 | Acc: 0.8867\n",
      "Batch 20/21 | Loss: 0.2361 | Acc: 0.9005\n",
      "Epoch 09 | Train Loss: 0.2361, Acc: 0.9005 | Val Loss: 0.2673, Acc: 0.9091, P: 0.9091, R: 0.9035, F1: 0.9060\n",
      "\n",
      "--- Epoch 10/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1909 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.2436 | Acc: 0.9219\n",
      "Batch 10/21 | Loss: 0.2186 | Acc: 0.9205\n",
      "Batch 15/21 | Loss: 0.2193 | Acc: 0.9258\n",
      "Batch 20/21 | Loss: 0.2242 | Acc: 0.9246\n",
      "Epoch 10 | Train Loss: 0.2242, Acc: 0.9246 | Val Loss: 0.2635, Acc: 0.9152, P: 0.9144, R: 0.9108, F1: 0.9124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_state_frozen, map_location=device))\n",
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if use_amp else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñ∂Ô∏è Phase: fold5_finetune | epochs=20 | lr=0.0001 | weight_decay=0.0001\n",
      "\n",
      "--- Epoch 1/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.3561 | Acc: 0.9062\n",
      "Batch 5/21 | Loss: 0.2991 | Acc: 0.8802\n",
      "Batch 10/21 | Loss: 0.3155 | Acc: 0.8580\n",
      "Batch 15/21 | Loss: 0.3258 | Acc: 0.8574\n",
      "Batch 20/21 | Loss: 0.3254 | Acc: 0.8597\n",
      "Epoch 01 | Train Loss: 0.3254, Acc: 0.8597 | Val Loss: 0.2516, Acc: 0.9273, P: 0.9253, R: 0.9253, F1: 0.9253\n",
      "\n",
      "--- Epoch 2/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1966 | Acc: 0.9062\n",
      "Batch 5/21 | Loss: 0.2063 | Acc: 0.9062\n",
      "Batch 10/21 | Loss: 0.1740 | Acc: 0.9205\n",
      "Batch 15/21 | Loss: 0.1773 | Acc: 0.9199\n",
      "Batch 20/21 | Loss: 0.1791 | Acc: 0.9246\n",
      "Epoch 02 | Train Loss: 0.1791, Acc: 0.9246 | Val Loss: 0.2400, Acc: 0.9152, P: 0.9115, R: 0.9210, F1: 0.9140\n",
      "\n",
      "--- Epoch 3/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0794 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.1332 | Acc: 0.9583\n",
      "Batch 10/21 | Loss: 0.1352 | Acc: 0.9545\n",
      "Batch 15/21 | Loss: 0.1596 | Acc: 0.9434\n",
      "Batch 20/21 | Loss: 0.1624 | Acc: 0.9442\n",
      "Epoch 03 | Train Loss: 0.1624, Acc: 0.9442 | Val Loss: 0.2679, Acc: 0.9212, P: 0.9242, R: 0.9139, F1: 0.9181\n",
      "\n",
      "--- Epoch 4/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.1139 | Acc: 0.9375\n",
      "Batch 5/21 | Loss: 0.0982 | Acc: 0.9531\n",
      "Batch 10/21 | Loss: 0.0875 | Acc: 0.9659\n",
      "Batch 15/21 | Loss: 0.0872 | Acc: 0.9648\n",
      "Batch 20/21 | Loss: 0.0811 | Acc: 0.9683\n",
      "Epoch 04 | Train Loss: 0.0811, Acc: 0.9683 | Val Loss: 0.2651, Acc: 0.9333, P: 0.9402, R: 0.9244, F1: 0.9304\n",
      "\n",
      "--- Epoch 5/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0821 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0889 | Acc: 0.9635\n",
      "Batch 10/21 | Loss: 0.0666 | Acc: 0.9716\n",
      "Batch 15/21 | Loss: 0.0657 | Acc: 0.9727\n",
      "Batch 20/21 | Loss: 0.0708 | Acc: 0.9729\n",
      "Epoch 05 | Train Loss: 0.0708, Acc: 0.9729 | Val Loss: 0.2407, Acc: 0.9152, P: 0.9117, R: 0.9149, F1: 0.9132\n",
      "\n",
      "--- Epoch 6/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0224 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0370 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0484 | Acc: 0.9773\n",
      "Batch 15/21 | Loss: 0.0666 | Acc: 0.9746\n",
      "Batch 20/21 | Loss: 0.0656 | Acc: 0.9744\n",
      "Epoch 06 | Train Loss: 0.0656, Acc: 0.9744 | Val Loss: 0.2461, Acc: 0.9212, P: 0.9198, R: 0.9180, F1: 0.9189\n",
      "\n",
      "--- Epoch 7/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0329 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0257 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0383 | Acc: 0.9830\n",
      "Batch 15/21 | Loss: 0.0409 | Acc: 0.9824\n",
      "Batch 20/21 | Loss: 0.0417 | Acc: 0.9834\n",
      "Epoch 07 | Train Loss: 0.0417, Acc: 0.9834 | Val Loss: 0.2797, Acc: 0.9212, P: 0.9242, R: 0.9139, F1: 0.9181\n",
      "\n",
      "--- Epoch 8/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0022 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0293 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0312 | Acc: 0.9886\n",
      "Batch 15/21 | Loss: 0.0276 | Acc: 0.9922\n",
      "Batch 20/21 | Loss: 0.0263 | Acc: 0.9925\n",
      "Epoch 08 | Train Loss: 0.0263, Acc: 0.9925 | Val Loss: 0.2896, Acc: 0.9333, P: 0.9370, R: 0.9264, F1: 0.9307\n",
      "\n",
      "--- Epoch 9/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0084 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0436 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0340 | Acc: 0.9886\n",
      "Batch 15/21 | Loss: 0.0338 | Acc: 0.9883\n",
      "Batch 20/21 | Loss: 0.0339 | Acc: 0.9864\n",
      "Epoch 09 | Train Loss: 0.0339, Acc: 0.9864 | Val Loss: 0.3055, Acc: 0.9394, P: 0.9449, R: 0.9316, F1: 0.9369\n",
      "\n",
      "--- Epoch 10/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0075 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0262 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0524 | Acc: 0.9830\n",
      "Batch 15/21 | Loss: 0.0492 | Acc: 0.9824\n",
      "Batch 20/21 | Loss: 0.0477 | Acc: 0.9819\n",
      "Epoch 10 | Train Loss: 0.0477, Acc: 0.9819 | Val Loss: 0.3150, Acc: 0.9212, P: 0.9217, R: 0.9160, F1: 0.9185\n",
      "\n",
      "--- Epoch 11/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0081 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0411 | Acc: 0.9844\n",
      "Batch 10/21 | Loss: 0.0464 | Acc: 0.9830\n",
      "Batch 15/21 | Loss: 0.0575 | Acc: 0.9766\n",
      "Batch 20/21 | Loss: 0.0624 | Acc: 0.9744\n",
      "Epoch 11 | Train Loss: 0.0624, Acc: 0.9744 | Val Loss: 0.2360, Acc: 0.9394, P: 0.9365, R: 0.9398, F1: 0.9380\n",
      "\n",
      "--- Epoch 12/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0242 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0574 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0482 | Acc: 0.9915\n",
      "Batch 15/21 | Loss: 0.0418 | Acc: 0.9922\n",
      "Batch 20/21 | Loss: 0.0432 | Acc: 0.9910\n",
      "Epoch 12 | Train Loss: 0.0432, Acc: 0.9910 | Val Loss: 0.2503, Acc: 0.9455, P: 0.9448, R: 0.9429, F1: 0.9438\n",
      "\n",
      "--- Epoch 13/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0016 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0164 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0116 | Acc: 0.9943\n",
      "Batch 15/21 | Loss: 0.0165 | Acc: 0.9922\n",
      "Batch 20/21 | Loss: 0.0155 | Acc: 0.9925\n",
      "Epoch 13 | Train Loss: 0.0155, Acc: 0.9925 | Val Loss: 0.3109, Acc: 0.9091, P: 0.9050, R: 0.9117, F1: 0.9074\n",
      "\n",
      "--- Epoch 14/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0096 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0248 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0202 | Acc: 0.9915\n",
      "Batch 15/21 | Loss: 0.0209 | Acc: 0.9902\n",
      "Batch 20/21 | Loss: 0.0215 | Acc: 0.9879\n",
      "Epoch 14 | Train Loss: 0.0215, Acc: 0.9879 | Val Loss: 0.2805, Acc: 0.9515, P: 0.9502, R: 0.9502, F1: 0.9502\n",
      "\n",
      "--- Epoch 15/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0006 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0056 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0125 | Acc: 0.9972\n",
      "Batch 15/21 | Loss: 0.0405 | Acc: 0.9922\n",
      "Batch 20/21 | Loss: 0.0452 | Acc: 0.9894\n",
      "Epoch 15 | Train Loss: 0.0452, Acc: 0.9894 | Val Loss: 0.4463, Acc: 0.9273, P: 0.9444, R: 0.9130, F1: 0.9230\n",
      "\n",
      "--- Epoch 16/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0364 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0418 | Acc: 0.9896\n",
      "Batch 10/21 | Loss: 0.0302 | Acc: 0.9915\n",
      "Batch 15/21 | Loss: 0.0292 | Acc: 0.9922\n",
      "Batch 20/21 | Loss: 0.0255 | Acc: 0.9940\n",
      "Epoch 16 | Train Loss: 0.0255, Acc: 0.9940 | Val Loss: 0.2831, Acc: 0.9455, P: 0.9571, R: 0.9348, F1: 0.9427\n",
      "\n",
      "--- Epoch 17/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0180 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0089 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0073 | Acc: 1.0000\n",
      "Batch 15/21 | Loss: 0.0242 | Acc: 0.9961\n",
      "Batch 20/21 | Loss: 0.0306 | Acc: 0.9925\n",
      "Epoch 17 | Train Loss: 0.0306, Acc: 0.9925 | Val Loss: 0.2735, Acc: 0.9515, P: 0.9577, R: 0.9441, F1: 0.9495\n",
      "\n",
      "--- Epoch 18/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0089 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0058 | Acc: 1.0000\n",
      "Batch 10/21 | Loss: 0.0069 | Acc: 1.0000\n",
      "Batch 15/21 | Loss: 0.0168 | Acc: 0.9980\n",
      "Batch 20/21 | Loss: 0.0155 | Acc: 0.9985\n",
      "Epoch 18 | Train Loss: 0.0155, Acc: 0.9985 | Val Loss: 0.2502, Acc: 0.9576, P: 0.9625, R: 0.9513, F1: 0.9559\n",
      "\n",
      "--- Epoch 19/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0358 | Acc: 0.9688\n",
      "Batch 5/21 | Loss: 0.0205 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0134 | Acc: 0.9972\n",
      "Batch 15/21 | Loss: 0.0115 | Acc: 0.9980\n",
      "Batch 20/21 | Loss: 0.0140 | Acc: 0.9970\n",
      "Epoch 19 | Train Loss: 0.0140, Acc: 0.9970 | Val Loss: 0.2405, Acc: 0.9394, P: 0.9377, R: 0.9377, F1: 0.9377\n",
      "\n",
      "--- Epoch 20/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/21 | Loss: 0.0086 | Acc: 1.0000\n",
      "Batch 5/21 | Loss: 0.0118 | Acc: 0.9948\n",
      "Batch 10/21 | Loss: 0.0083 | Acc: 0.9972\n",
      "Batch 15/21 | Loss: 0.0174 | Acc: 0.9941\n",
      "Batch 20/21 | Loss: 0.0154 | Acc: 0.9955\n",
      "Epoch 20 | Train Loss: 0.0154, Acc: 0.9955 | Val Loss: 0.2685, Acc: 0.9333, P: 0.9299, R: 0.9346, F1: 0.9319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cauba\\AppData\\Local\\Temp\\ipykernel_5988\\3359186712.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_state_ft, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Saved results: models\\convnext_tiny\\convnext_tiny_kfold_results.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"convnext_tiny\" \n",
    "k = 5                \n",
    "epochs_frozen = 10     \n",
    "epochs_ft = 20          \n",
    "batch_size = 32\n",
    "img_size = (224, 224)\n",
    "base_lr = 1e-3\n",
    "ft_lr = 1e-4\n",
    "weight_decay = 1e-4     \n",
    "pretrained = True\n",
    "\n",
    "run_kfold_training(\n",
    "    model_name=model_name,\n",
    "    dataset_path=dataset_path,\n",
    "    k=k,\n",
    "    epochs_frozen=epochs_frozen,\n",
    "    epochs_ft=epochs_ft,\n",
    "    batch_size=batch_size,\n",
    "    img_size=img_size,\n",
    "    base_lr=base_lr,\n",
    "    ft_lr=ft_lr,\n",
    "    weight_decay=weight_decay,\n",
    "    pretrained=pretrained\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967ddfad",
   "metadata": {},
   "source": [
    "- ViT-B16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012977f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdf24c8c",
   "metadata": {},
   "source": [
    "- CoatNeT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a95c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
